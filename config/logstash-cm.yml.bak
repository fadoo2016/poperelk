apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: elk
data:
  logstash.yml: |
    http.host: 0.0.0.0
    node.name: logstash
    http.port: 9600
    config.reload.automatic: true
    xpack.monitoring.enabled: true
    xpack.monitoring.elasticsearch.username: logstash_system
    xpack.monitoring.elasticsearch.password: abcd1234
    xpack.monitoring.elasticsearch.hosts: ["http://elasticsearch:9200"]
    xpack.monitoring.collection.interval: 10s

  pipelines.yml: |
    - pipeline.id: syslog-server
      config.string: |
        input { syslog { port => 8088 } }
        filter {
          if ([message] =~ "path=\"/build/assets/") {
            drop {}
          }
          mutate {
            gsub => [ "message", "d.8cfd9efd-5870-4ab1-aba8-3a36afb21daa", "" ]
          }
          date {
              match => ["access_time", "dd/MMM/YYYY:HH:mm:ss Z", "UNIX", "yyyy-MM-dd HH:mm:ss", "dd-MMM-yyyy HH:mm:ss"]
              target => "@timestamp"
              timezone => "Asia/Shanghai"
          }
        }
        output {
          pipeline { send_to => IND }
        }
    - pipeline.id: index-processing
      config.string: |
        input {
          pipeline {
            address => IND
          }
        }
        filter {
          grok {
            match => {
              "message" => "(?<app_type>heroku router)%{DATA}(?<request_id>(?<=request_id=)[\w-]{20,200})"
            }
            add_field => { "type" => "heroku" }
          }

          grok {
            match => {
              "message" => "(?<app_type>app web\.\d+)%{DATA}%{COMBINEDAPACHELOG} %{QS:x_forworded_for} - \"(?<request_id>[\w-]{20,200})\""
            }
            add_field => { "type" => "nginx" }
          }

          grok {
            match => {
              "message" => "(?<app_type>app web\.\d+)%{DATA}\[(?<date>[\d\-\s:]+)\]%{DATA}%{IP:ip}%{DATA}(?<request_id>(?<=request_id:)[\w-]+)%{DATA}(?<role>(?<=role: )[^\s]+)%{DATA}(?<UserID>(?<=UserID:)\d)%{DATA}(?<path>(?<=request:)[^\|]+)%{DATA}:(?<params>[^$]+)"
            }
            add_field => { "type" => "laravel" }
          }
        }
        output {
          #stdout {}
          pipeline { send_to => MUL }
        }
    - pipeline.id: multi-processing
      config.string: |
        input {
          pipeline {
            address => MUL
          }
        }
        filter {
          if ([request_id] !~ "[\w-]{20,200}") {
            drop{}
          }
          ruby {
            init => "@@ruby_tag= ''"
            code => "
                event.set('[ruby_tag]',@@ruby_tag)
                str='[LOG@'+event.get('[type]')+']:'
                if @@ruby_tag==event.get('[request_id]')
                  event.remove('[request_id]')
                  str='  '+str
                else
                  @@ruby_tag=event.get('[request_id]')
                  event.set('[type]','combined-head')
                end
                event.set('[message]',str+event.get('[message]'))
            "
          }
        }
        output {
          #stdout {}
          pipeline { send_to => COM }
        }
    - pipeline.id: combine-processing
      config.string: |
        input {
          pipeline {
            address => COM
            #codec => multiline {
            #  pattern => "^\s"
            #  what => "previous"
            #  #negate => true
            #}
          }
        }
        filter {
          multiline {
            pattern => "^\s"
            negate => false
            what => "previous"
          }
        }
        output {
          stdout {}
          elasticsearch {
            hosts => ["elasticsearch:9200"]
            index => "combinded"
            user => "elastic"
            password => "abcd1234"
          }
        }
